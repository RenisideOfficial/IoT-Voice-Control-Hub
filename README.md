---
# ğŸ™ï¸ Real-Time Voice Recognition with WebSockets

A lightweight system for **live speech-to-text transcription** using WebSockets. The project streams microphone audio to the backend, transcribes it in real-time, and displays the results instantly in the browser.
---

## âœ¨ Features

- ğŸ¤ **Microphone recording** directly in the browser
- ğŸ”— **WebSocket streaming** for low-latency communication
- ğŸ“ **Real-time transcription** (word-by-word / sentence-by-sentence)
- ğŸ“œ **Final transcripts panel** with auto-scrolling
- âš¡ Powered by **Django Channels** and a modular `voice` engine

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/RenisideOfficial/Real-Time-Speech-Recognition.git
cd Real-Time-Speech-Recognition
```

### 2. Backend setup (Django + Channels)

```bash
python -m venv .venv
source '.venv'/bin/activate   # On Windows: . 'venv'\Scripts\activate
pip install -r requirements.txt
```

Run the Django server (with Daphne or Uvicorn) on the terminal:

```bash
daphne main.asgi:application
```

### 3. Frontend setup

Simply open the `index.html` in your browser

---

## ğŸ“‚ Project Structure

```
alpha/
â”‚
â”‚â”€â”€ backend/                        # Django backend
â”‚   â”œâ”€â”€ asgi.py                     # ASGI entrypoint for Django Channels
â”‚   â”œâ”€â”€ settings.py                 # Django project configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ commands/                   # WebSocket app for handling voice commands
â”‚   â”‚   â”œâ”€â”€ consumers.py            # WebSocket consumer (streams audio, returns transcripts)
â”‚   â”‚   â”œâ”€â”€ routing.py              # WebSocket URL routing
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ voice/                      # Voice engine logic
â”‚   â”‚   â”œâ”€â”€ speech.py               # Handles voice chunking & speech recognition
â”‚   â”‚   â””â”€â”€ __init__.py             # Makes `voice` a Python package
â”‚   â”‚
â”‚   â”œâ”€â”€ main/                       # Core Django app
â”‚   â”‚   â”œâ”€â”€ wsgi.py                 # WSGI entrypoint (if needed for non-async servers)
â”‚   â”‚   â””â”€â”€ urls.py                 # URL routing for HTTP views
â”‚   â”‚
â”‚   â””â”€â”€ requirements.txt            # Python dependencies (Django, Channels, SpeechRecognition, etc.)
â”‚
â”‚â”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                  # Main UI page (records voice + displays transcripts)
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â””â”€â”€ script.js               # Handles WebSocket connection & real-time transcription
â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â””â”€â”€ styles.css              # Basic styling for panels, transcripts, buttons
â”‚   â””â”€â”€ img/                        # Any icons, assets, or images used in the UI
â”‚
â”‚â”€â”€ .gitignore                      # Ignored files (venv, DBs, node_modules, etc.)
â”‚â”€â”€ README.md                       # Project documentation

```

---

## ğŸ–¼ï¸ Demo Flow

1. Click **Start Recording**
2. Speak into your microphone
3. Watch the **transcripts appear in real-time**
4. Final results are stored in the transcripts panel

---

## ğŸ”§ Tech Stack

- **Backend:** Django, Django Channels, WebSockets
- **Speech:** SpeechRecognition / Whisper (configurable)
- **Frontend:** Vanilla JS + WebSocket API

---

## ğŸ“Œ Roadmap

- [ ] Add **speaker diarization** (whoâ€™s talking)
- [ ] Support **multiple languages**
- [ ] Add **real-time translation**
- [ ] Store transcripts in a database

---

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first to discuss what youâ€™d like to change.

---

## ğŸ“œ License

MIT License Â© 2025 Ezika Chinweike

---
